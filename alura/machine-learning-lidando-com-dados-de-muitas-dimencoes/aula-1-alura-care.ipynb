{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnostico</th>\n",
       "      <th>exame_1</th>\n",
       "      <th>exame_2</th>\n",
       "      <th>exame_3</th>\n",
       "      <th>exame_4</th>\n",
       "      <th>exame_5</th>\n",
       "      <th>exame_6</th>\n",
       "      <th>exame_7</th>\n",
       "      <th>exame_8</th>\n",
       "      <th>...</th>\n",
       "      <th>exame_24</th>\n",
       "      <th>exame_25</th>\n",
       "      <th>exame_26</th>\n",
       "      <th>exame_27</th>\n",
       "      <th>exame_28</th>\n",
       "      <th>exame_29</th>\n",
       "      <th>exame_30</th>\n",
       "      <th>exame_31</th>\n",
       "      <th>exame_32</th>\n",
       "      <th>exame_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>...</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>...</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>103.78</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>...</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>...</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.854454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnostico  exame_1  exame_2  exame_3  exame_4  exame_5  exame_6   \n",
       "0    842302           M    17.99    10.38   122.80   103.78   1001.0  0.11840  \\\n",
       "1    842517           M    20.57    17.77   132.90   103.78   1326.0  0.08474   \n",
       "2  84300903           M    19.69    21.25   130.00   103.78   1203.0  0.10960   \n",
       "3  84348301           M    11.42    20.38    77.58   103.78    386.1  0.14250   \n",
       "4  84358402           M    20.29    14.34   135.10   103.78   1297.0  0.10030   \n",
       "\n",
       "   exame_7  exame_8  ...  exame_24  exame_25  exame_26  exame_27  exame_28   \n",
       "0  0.27760   0.3001  ...    184.60    2019.0    0.1622    0.6656    0.7119  \\\n",
       "1  0.07864   0.0869  ...    158.80    1956.0    0.1238    0.1866    0.2416   \n",
       "2  0.15990   0.1974  ...    152.50    1709.0    0.1444    0.4245    0.4504   \n",
       "3  0.28390   0.2414  ...     98.87     567.7    0.2098    0.8663    0.6869   \n",
       "4  0.13280   0.1980  ...    152.20    1575.0    0.1374    0.2050    0.4000   \n",
       "\n",
       "   exame_29  exame_30  exame_31  exame_32  exame_33  \n",
       "0     0.786    0.2654    0.4601   0.11890       NaN  \n",
       "1     0.786    0.1860    0.2750   0.08902       NaN  \n",
       "2     0.786    0.2430    0.3613   0.08758       NaN  \n",
       "3     0.786    0.2575    0.6638   0.17300       NaN  \n",
       "4     0.786    0.1625    0.2364   0.07678  0.854454  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultados_exames = pd.read_csv('exames.csv')\n",
    "resultados_exames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import random\n",
    "\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "valores_exames = resultados_exames.drop(columns=['id', 'diagnostico'])\n",
    "diagnostico = resultados_exames.diagnostico\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames, diagnostico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exame_1</th>\n",
       "      <th>exame_2</th>\n",
       "      <th>exame_3</th>\n",
       "      <th>exame_4</th>\n",
       "      <th>exame_5</th>\n",
       "      <th>exame_6</th>\n",
       "      <th>exame_7</th>\n",
       "      <th>exame_8</th>\n",
       "      <th>exame_9</th>\n",
       "      <th>exame_10</th>\n",
       "      <th>...</th>\n",
       "      <th>exame_24</th>\n",
       "      <th>exame_25</th>\n",
       "      <th>exame_26</th>\n",
       "      <th>exame_27</th>\n",
       "      <th>exame_28</th>\n",
       "      <th>exame_29</th>\n",
       "      <th>exame_30</th>\n",
       "      <th>exame_31</th>\n",
       "      <th>exame_32</th>\n",
       "      <th>exame_33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>10.860</td>\n",
       "      <td>21.48</td>\n",
       "      <td>68.51</td>\n",
       "      <td>103.78</td>\n",
       "      <td>360.5</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.04227</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1661</td>\n",
       "      <td>...</td>\n",
       "      <td>74.08</td>\n",
       "      <td>412.3</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.07348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06592</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>10.940</td>\n",
       "      <td>18.59</td>\n",
       "      <td>70.39</td>\n",
       "      <td>103.78</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.10040</td>\n",
       "      <td>0.07460</td>\n",
       "      <td>0.04944</td>\n",
       "      <td>0.02932</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>...</td>\n",
       "      <td>82.76</td>\n",
       "      <td>472.4</td>\n",
       "      <td>0.13630</td>\n",
       "      <td>0.16440</td>\n",
       "      <td>0.14120</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.07887</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07732</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>17.460</td>\n",
       "      <td>39.28</td>\n",
       "      <td>113.40</td>\n",
       "      <td>103.78</td>\n",
       "      <td>920.6</td>\n",
       "      <td>0.09812</td>\n",
       "      <td>0.12980</td>\n",
       "      <td>0.14170</td>\n",
       "      <td>0.08811</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>141.20</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>0.13650</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.32410</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.20660</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.08496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>13.530</td>\n",
       "      <td>10.94</td>\n",
       "      <td>87.91</td>\n",
       "      <td>103.78</td>\n",
       "      <td>559.2</td>\n",
       "      <td>0.12910</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>0.06556</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>...</td>\n",
       "      <td>91.36</td>\n",
       "      <td>605.5</td>\n",
       "      <td>0.14510</td>\n",
       "      <td>0.13790</td>\n",
       "      <td>0.08539</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.07407</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.07191</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>13.000</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>103.78</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.01206</td>\n",
       "      <td>0.01762</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>...</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.05921</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>20.090</td>\n",
       "      <td>23.86</td>\n",
       "      <td>134.70</td>\n",
       "      <td>103.78</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.18380</td>\n",
       "      <td>0.22830</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>...</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>0.13470</td>\n",
       "      <td>0.33910</td>\n",
       "      <td>0.49320</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.19230</td>\n",
       "      <td>0.3294</td>\n",
       "      <td>0.09469</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>12.890</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>103.78</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>11.060</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>103.78</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.05397</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>...</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "      <td>0.845748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>13.650</td>\n",
       "      <td>13.16</td>\n",
       "      <td>87.88</td>\n",
       "      <td>103.78</td>\n",
       "      <td>568.9</td>\n",
       "      <td>0.09646</td>\n",
       "      <td>0.08711</td>\n",
       "      <td>0.03888</td>\n",
       "      <td>0.02563</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>...</td>\n",
       "      <td>99.71</td>\n",
       "      <td>706.2</td>\n",
       "      <td>0.13110</td>\n",
       "      <td>0.24740</td>\n",
       "      <td>0.17590</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.08056</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>0.08718</td>\n",
       "      <td>0.069723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>103.78</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>...</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.16300</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     exame_1  exame_2  exame_3  exame_4  exame_5  exame_6  exame_7  exame_8   \n",
       "550   10.860    21.48    68.51   103.78    360.5  0.07431  0.04227  0.00000  \\\n",
       "405   10.940    18.59    70.39   103.78    370.0  0.10040  0.07460  0.04944   \n",
       "239   17.460    39.28   113.40   103.78    920.6  0.09812  0.12980  0.14170   \n",
       "76    13.530    10.94    87.91   103.78    559.2  0.12910  0.10470  0.06877   \n",
       "458   13.000    25.13    82.61   103.78    520.2  0.08369  0.05073  0.01206   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "302   20.090    23.86   134.70   103.78   1247.0  0.10800  0.18380  0.22830   \n",
       "287   12.890    13.12    81.89   103.78    515.9  0.06955  0.03729  0.02260   \n",
       "342   11.060    14.96    71.49   103.78    373.9  0.10330  0.09097  0.05397   \n",
       "220   13.650    13.16    87.88   103.78    568.9  0.09646  0.08711  0.03888   \n",
       "151    8.219    20.70    53.27   103.78    203.9  0.09405  0.13050  0.13210   \n",
       "\n",
       "     exame_9  exame_10  ...  exame_24  exame_25  exame_26  exame_27  exame_28   \n",
       "550  0.00000    0.1661  ...     74.08     412.3   0.10010   0.07348   0.00000  \\\n",
       "405  0.02932    0.1486  ...     82.76     472.4   0.13630   0.16440   0.14120   \n",
       "239  0.08811    0.1809  ...    141.20    1408.0   0.13650   0.37350   0.32410   \n",
       "76   0.06556    0.2403  ...     91.36     605.5   0.14510   0.13790   0.08539   \n",
       "458  0.01762    0.1667  ...     91.06     628.5   0.12180   0.10930   0.04462   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "302  0.12800    0.2249  ...    158.80    1696.0   0.13470   0.33910   0.49320   \n",
       "287  0.01171    0.1337  ...     87.40     577.0   0.09616   0.11470   0.11860   \n",
       "342  0.03341    0.1776  ...     79.76     440.0   0.14180   0.22100   0.22990   \n",
       "220  0.02563    0.1360  ...     99.71     706.2   0.13110   0.24740   0.17590   \n",
       "151  0.02168    0.2222  ...     58.08     249.8   0.16300   0.43100   0.53810   \n",
       "\n",
       "     exame_29  exame_30  exame_31  exame_32  exame_33  \n",
       "550     0.786   0.00000    0.2458   0.06592       NaN  \n",
       "405     0.786   0.07887    0.2251   0.07732       NaN  \n",
       "239     0.786   0.20660    0.2853   0.08496       NaN  \n",
       "76      0.786   0.07407    0.2710   0.07191       NaN  \n",
       "458     0.786   0.05921    0.2306   0.06291       NaN  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "302     0.786   0.19230    0.3294   0.09469       NaN  \n",
       "287     0.786   0.05366    0.2309   0.06915       NaN  \n",
       "342     0.786   0.10750    0.3301   0.09080  0.845748  \n",
       "220     0.786   0.08056    0.2380   0.08718  0.069723  \n",
       "151     0.786   0.07879    0.3322   0.14860       NaN  \n",
       "\n",
       "[143 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m classificador \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# ajustar modelo aos dados\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m classificador\u001b[39m.\u001b[39;49mfit(treino_x, treino_y)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(classificador\u001b[39m.\u001b[39mscore(teste_x, teste_y))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/machine-learning-lidando-com-dados-de-muit-iugUX1Bp/lib64/python3.11/site-packages/sklearn/ensemble/_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/machine-learning-lidando-com-dados-de-muit-iugUX1Bp/lib64/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/machine-learning-lidando-com-dados-de-muit-iugUX1Bp/lib64/python3.11/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/machine-learning-lidando-com-dados-de-muit-iugUX1Bp/lib64/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/machine-learning-lidando-com-dados-de-muit-iugUX1Bp/lib64/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instanciar objeto do modelo\n",
    "classificador = RandomForestClassifier(n_estimators=100)\n",
    "# ajustar modelo aos dados\n",
    "classificador.fit(treino_x, treino_y)\n",
    "print(classificador.score(teste_x, teste_y))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "diagnostico      0\n",
       "exame_1          0\n",
       "exame_2          0\n",
       "exame_3          0\n",
       "exame_4          0\n",
       "exame_5          0\n",
       "exame_6          0\n",
       "exame_7          0\n",
       "exame_8          0\n",
       "exame_9          0\n",
       "exame_10         0\n",
       "exame_11         0\n",
       "exame_12         0\n",
       "exame_13         0\n",
       "exame_14         0\n",
       "exame_15         0\n",
       "exame_16         0\n",
       "exame_17         0\n",
       "exame_18         0\n",
       "exame_19         0\n",
       "exame_20         0\n",
       "exame_21         0\n",
       "exame_22         0\n",
       "exame_23         0\n",
       "exame_24         0\n",
       "exame_25         0\n",
       "exame_26         0\n",
       "exame_27         0\n",
       "exame_28         0\n",
       "exame_29         0\n",
       "exame_30         0\n",
       "exame_31         0\n",
       "exame_32         0\n",
       "exame_33       419\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isnull() retorna True caso exista um valor nulo na posição\n",
    "resultados_exames.isnull().sum()\n",
    "# ao aplicar o .sum() na saida do isnull(), temos para cada coluna o numero de linhas com valor nulo\n",
    "# se uma coluna tem muitas celulas vazias, devemos exclui-la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da classificação:  92.39766081871345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from numpy import random\n",
    "\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "\n",
    "valores_exames = resultados_exames.drop(columns=['id', 'diagnostico'])\n",
    "diagnostico = resultados_exames.diagnostico\n",
    "# remover a coluna 33 (tem muitos valores nulos)\n",
    "valores_exames_v1 = valores_exames.drop(columns=['exame_33'])\n",
    "\n",
    "treino_x, teste_x, treino_y, teste_y = train_test_split(valores_exames_v1, diagnostico, test_size=0.3)\n",
    "\n",
    "\n",
    "# instanciar objeto do modelo\n",
    "classificador = RandomForestClassifier(n_estimators=100)\n",
    "# ajustar modelo aos dados\n",
    "classificador.fit(treino_x, treino_y)\n",
    "print('Resultado da classificação: ', (classificador.score(teste_x, teste_y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da classificação boba:  66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "# compara resultado obtido com o dummyClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "SEED = 123143\n",
    "random.seed(SEED)\n",
    "classificador_bobo = DummyClassifier(strategy='most_frequent')\n",
    "classificador_bobo.fit(treino_x, treino_y)\n",
    "print('Resultado da classificação boba: ', (classificador_bobo.score(teste_x, teste_y) * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(x='exames', y='valores', hue='diagnostico', data=dados_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-lidando-com-dados-de-muit-iugUX1Bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
